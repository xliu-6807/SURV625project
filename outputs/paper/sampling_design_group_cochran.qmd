---
title: "Michigan Teen Smoking and Drug Use Survey Sample Design"
format:
  jasa-pdf:
    keep-tex: true  
    journal:
      blinded: false
  jasa-html: default
date: last-modified
author:
  - name: Kevin Linares
  - name: Jianing Zou
  - name: Weishan Jiang
  - name: Xiaoqing Liu
    affiliations:
      - name: University of Maryland
abstract: |
  
  
editor: 
  markdown: 
    wrap: sentence
---

```{r include=FALSE}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, comment = FALSE)

pacman::p_load(readxl, writexl, MESS, # used for linking
              kableExtra, viridis, ggthemes, knitr, sampling, tidyverse)

options(scipen=999)


```

## Introduction {#sec-intro}

The State of Michigan Department of Education (MDE) requires data to monitor teenage smoking and drug use, partly to assess compliance with tobacco industry settlements.
This report details the design of a statewide probability sample of Michigan teenagers (enrolled students in grades 7-12) developed to meet the Department's needs.
The objective was to create a cost-effective sample design capable of producing estimates for key variables with desired mean and sampling variance for both the state overall and each of the nine official school regions.
Based on cost considerations and a review of alternatives, a two-stage school-based sample design was chosen by the client.
We outline in this report the overall design, stratification and allocation plan, selection procedures, and estimation methods.
Our budget consist of a total of \$500,000; each school $C_n$ cost \$3,000 and each student $C_m$ cost \$50 to sample.\

The MDE is specifically interested in three outcome variables; every smoked one cigarette, every smoked marijuana, and age when first approach to smoke cigarettes or marijuana.
Moreover, they provided us with expected levels of precision for the survey in terms of the expected means and coefficient of variation (CV=0.05) which can be seen in Table 1.

```{r}

# build dataframe with inputs
MI_school_samples <- tibble(
  Outcome = c("smoked_cig", "smoked_mj", "age_approached"),
  type = c("prop", "prop", "mean"),
  desire_cv = rep(.05, 3),
  expect_mean = c(.25, .15, 12),
) 

MI_school_samples |> 
  kable(caption="Key Variables and Desired Levels of Precision ",
        col.names = c("Outcome", "Type", "Desired CV", "Expected Mean"),  
        align = "c", booktabs = TRUE) 
```

Given the desired levels of precision, we can compute the desired simple random sample (SRS) sample sizes when CV =.05 as $n = \frac{s^2}{se^2}$.
We first must calculate the element variance for each key variable.
For proportions we use $\hat{p}(1-\hat{p})$, while for age we simply just square the estimated standard deviation of 1 that was given to us, $v(\bar{y}) = \sigma^2$.
We then calculate the standard error as $se(\hat{p}) = CV \times \hat{p}$.
Finally, we estimate the desired sampling variance as $var(\hat{p}) =  se(\hat{p})^2 \text{, where }  se(\hat{p}) = \sqrt{var(\hat{p})}$.
We show these results in Table 2, and note that these desired levels of precision would lead to large differences in sample sizes for each target variable.
Therefore, we may wish to consider a more complex survey design.

```{r}

MI_school_samples <- MI_school_samples |> 
  mutate(
    # compute element variance
    var = if_else(type=="prop", # for proportions
                               expect_mean * (1 - expect_mean), 
                               if_else(type=="mean",# for means
                                       1^2, NA)),
    # compute stand dev
    sd = sqrt(var),
    # compute standard error
    se = desire_cv * expect_mean,
    # compute desired sample variance
    V = se^2,
    SRS_n = round(var / V))


MI_school_samples |> select(-2:-4 ) |> 
  kable(caption="Estimating SRS Desired Sample Size",
        col.names = c("Outcome", "Element Variance", "SD", "SE", "Sampling Variables", 
                      "SRS N"),  
        align = "c", booktabs = TRUE) 
```

## Sampling Design {#sec-meth}

We propose a two-stage stratified cluster sampling as a complex survey sampling method for this project combining stratification with multi-stage cluster sampling.
First, the entire population is divided into mutually exclusive and collectively exhausted subgroups called strata, based on shared characteristics relevant to the study (e.g., geographic region).
Then, within each of these strata, the first stage of sampling occurs: a random sample of clusters (natural groupings like schools) is selected, and are called primary sampling unts (PSUs).
In the second stage, a random sample of individual elements known as secondary sampling units (SSUs), such as students, are drawn from within each of the clusters selected in the first stage.
This approach aims to improve sample efficiency and representation by ensuring subgroups are included (i.e., stratification) while reducing costs and logistical challenges associated with sampling individuals across large geographic areas.

The MDE has given us the 2024 7th through 12th grade student headcount for each public and private school within each of the nine regions resulting in a target frame of $830,138$ across $2,443$ schools (78% Public).
Schools in the first stage will be selected with probability proportional to student body size (PPeS).
The proportionate allocation $M_h / \sum M_h$ where $M_h$ is the total number of students in stratum $h$, will be used to determine school number selection in the first stage.
Table 3 presents for each of the 9 strata total students, number of schools, and proportionate allocation.

```{r}

school_frame <- read_xls(
  "~/work/d/SURV625project/data/MI_school_frame_head_counts.xls")


# region counts
strata_Prop_allocate <- school_frame |> 
  group_by(Region) |> 
  reframe(M_h = sum(tot_all), # total of students in stratum
         N_h = n()) |> # total of schools in stratum
  mutate(prop_allocation = M_h/sum(M_h)) 

strata_Prop_allocate |> 
   kable(caption="Proportionate Allocation Across Strata",
        col.names = c("Region", "Total Student", "Total Schools", 
                      "Proportionate Allocation"),  
        align = "c", booktabs = TRUE) 


```

We obtained design effects (DEFF) estimates (DEFF_cig=2.5, DEFF_mj=2.0, DEFF_age=1.7) from a similar pilot study of 7,500 students based on on 150 schools with 50 students each, and based on these we estimate the rate of homogeneity $roh$ for each target variable.
We use the provided DEFFs to estimate $roh$ as $\hat{roh} = \frac{DEFF-1}{m-1}$, where $m$ is the total sampled students in the pilot study, to consider alternative cluster sample designs along with cost-considerations.
Table 4 provides the $roh$ estimate for each target variable.

```{r}
nm <- 7500
n <- 150
m <- nm / n

MI_school_samples <- MI_school_samples |> 
  # add deff and roh to our table
  mutate(desire_deff = c(2.5, 2.0, 1.7),
         # compute roh
         roh = (desire_deff - 1) / (m - 1),
         )

MI_school_samples |> 
  select(Outcome, desire_deff, roh) |>  
    kable(caption="We Use Pilot Study DEFFs to Estimate roh",
        col.names = c("Outcome", "DEFF", "roh"),  
        align = "c", booktabs = TRUE) 
```

### *Sampling Within Budget*

Recall that our budget cost constraints as the cost per cluster as $c_n = \$3,000$ and cost per student as $c_m = \$50$, with a total budget constraint of $C = \$500,000$.
We can use the $roh$estimates along with these costs to estimate the optimum subsample size $m_{opt}$ needed to achieve the desired precision as $m_{opt} = \sqrt{\frac{c_n}{c_m} \frac{1-roh}{roh}}$.
Note that since we have three target variables we also have three separate $roh$ estimates and thus three $m_{opt}$ estimates.
Similarly, we can use $m_{opt}$ to estimate the number of schools $n_{opt}$ to sample, $n_{opt} = \frac{C}{c_n + m_{opt} \times c_m}$ .
Finally, we compute new DEFF for each variable as $roh$ is portable and since we already computed $m_{opt}$ as $DEFF_{new} = 1 + (m_{opt} - 1) \times roh$.
By multiplying $m_{opt} \times n_{opt}$ for each variable we also get the total subsample size, as well as compute the total cost using $n_{opt} \times c_n + n_{opt} \times m_{opt} \times c_m$.
Table 5 shows for each target variable $m_{opt}$, $n_{opt}$, $DEFF_{new}$, total subsample size denoted by $total_{nm}$, and the total cost.
Notice that our $DEFF_{new}$ estimates are close to those from the pilot study since again we used these to compute $roh$ which is portable for estimating new design effects.

```{r}

c_n = 3000 # cost per cluster
c_m = 50 # cost per element within cluster
C = 500000 # total budget

MI_school_samples <- MI_school_samples |> 
  mutate(
    # compute optimum m size
    m_opt = sqrt( (c_n / c_m) * ( (1-roh)/roh) ),
    n_opt = C / (c_n + m_opt * c_m),
    # compute new deff
    deff_new = 1 + (m_opt-1) * roh,
     # compute total SSU
    total_nm = m_opt * n_opt)

MI_school_samples |> 
  select(Outcome, m_opt, n_opt, deff_new, total_nm) |> 
  mutate(cost = (c_n * n_opt) + (c_m * n_opt * m_opt),
         cost = scales::dollar(cost),
         Outcome = ifelse(Outcome == "age_approached_to_smoke", 
                          "age_smoke", Outcome),
         Option = 1:3) |>
  kable(caption="Estimating New DEFF and Total Cost",
        align = "c", booktabs = TRUE) 

# note, 88 * c_n + 88 * 53 * c_m = $497,200
```

### *Evaluating Alternative Clustering Designs*

We are left with a dilemma since we now have three subsample sizes that we can use, thus giving us three clustering design options to choose from.
Using the $m_{opt}$ values from table 5 as our three options, we iterate over each set of three target variables using these values to recompute for each target variable a new design effect and evaluate the estimated sampling variance for each design.
We estimate the SRS sampling variance as $var_{srs} = \frac{var}{total_{nm} - 1}$ where var is the sampling variance calculated from the pilot study and the denominator is the degrees of freedom.
Additionally, we estimate the sampling variance for the clustering design as $var_{crs} = var_{srs} \times deff_{new}$.
After estimating $var_{crs}$, we can square it to estimate a standard error, $se=\sqrt{var_{crs}}$ to use to estimate 95% confidence intervals for the estimated means.
Additionally, in our evaluation of $m_{opt}$ we can determine if the estimated sampling variance from the complex design is smaller than what is desired from MDE, therefore Table 6 shows sampling variances, standard errors, confidence intervals, and a variance check (e.g., "Y" = yes if \<= to desired sampling variance) for each target variable using the $m_{opt}$ options in Table 5.

```{r}

map_dfr(seq(1,3), function(x){
  
  MI_school_samples |> 
  # we can print projected total cost for n=50
  mutate(m_opt = m_opt[x], # optimum m from first row
         n_opt = n_opt[x],
         total_nm = m_opt*n_opt,
         # calculate new deff
         deff_new = 1 + (m_opt-1) * roh,
         # recalcualte element variance
         var = c(.24, .1275, 9),
         # calcualte SRS variance
         var_srs =  var / (total_nm - 1),
         # calculate complex design variance
         var_crs = var_srs * deff_new,
          # compute confidence intervals
         se = sqrt(var_crs),
         lower = expect_mean  - 1.96*se,
         upper = expect_mean + 1.96*se,
        # flag if var_crs is lower or = to desired sampling var
         var_ck = ifelse(var_crs <= V, "Y", "N"),
        Option = x,
  ) 
    
  
}) |> 
  select(Outcome, Option, deff_new, var_srs, var_crs, se, lower, upper, var_ck) |> 
  mutate_at(3:8, round, 6) |> 
  kable(caption="Evaluating Alternative Clustering Designs",
        align = "c", booktabs = TRUE) 


# total pop
N <- school_frame |> tally(tot_all) |> pull()

# optimum n
total_nm <- MI_school_samples |> 
  slice(2) |> # second design option 
  summarise(m_opt*n_opt) |> 
  pull()


samp_frac <- total_nm / N


```

Upon evaluation of options from Table 6, we determine that option 2 has reasonable estimated design effects comparable to those from the pilot study as well as it is the only option to pass the estimated sampling variance check we designed.
Option 2 with $m_{opt} = 53, n_{opt} = 88$ would cost a total of \$497,200.
Since the total student population is `r N` and our now target sample is `r round(total_nm)` we can estimate the sampling fraction to be $f = n/N$ = `r samp_frac`.
The sampling fraction is the ratio of the sample size to the population size, and this estimate translates to the sample comprises approximately 0.57% of the total student population.
In this case, the sampling fraction is low and the finite population correction factor is not needed for calculating variances to adjust for the fact that sampling without replacement from a finite population reduces variability compared to sampling from an infinite population.

### *Non-response Adjustments*

```{r}
# response rates
school_rr <- .30
student_rr <- .70
# Given values
n_opt <- MI_school_samples |> 
  slice(2) |> select(n_opt) |> 
  pull() / school_rr

m_opt <- MI_school_samples |> 
  slice(2) |> select(m_opt) |> 
  pull() / student_rr


```

The MDE anticipates 30% school response rates and 70% among students; therefore, we adjust the number of schools and within-school target by multiplying $m_{opt} \times RR_{student} = 53 \times .70$ = `r m_opt` students and for schools $n_{opt} \times RR_{schools} =  \times .30$ = `r n_opt`.
We use these values to allocate the number of clusters for each strata based on the proportion allocated we calculated.

## Stage 1 Selection

We consider stratified PPeS selection of schools from each strata by first sorting the list of schools to achieve implicit stratification.
How we sort is by taking the number of 9th through 12th grade for each school divided by the total student body and descend order, and in this way we hypothesize that schools with older students are more likely to be positively associated with the target variables.
For each strata $h$ we assign our adjusted $n_{opt} \times proportionate \_ allocation$ estimated earlier to calculate the number of schools to sample, denoted as $n_h$ in Table 7.
We use $n_h$ to calculated in this Table the sampling interval $k_h = \frac{\sum_{i \ in h} MOS_{hi}}{n_h}$ where $MOS_{hi}$ is the measure of size (MOS), total student head-count, for each school $i$ in strata $h$.
The $k_h$ parameter is an important component of systematic sampling to determine how frequently units are selected from an ordered list.
To conduct this selection, we randomly select a number between 1 and $k_h$ for selecting schools from the list, which is captured in Table 7 as $RN$.

```{r}
set.seed(9999) 

# Compute proportional allocation of clusters to each stratum
region_summary <- strata_Prop_allocate |> 
  # Ensure at least 1 cluster per
  mutate(n_h = n_opt * prop_allocation,
                     N_h = as.double(N_h)) |> 
  group_by(Region) |> 
  reframe(across(where(is.double), ~ sum(.x))) |> 
  mutate(k_h = M_h / round(n_h)) |>    # zone size
  # create random start values
  rowwise() |> 
  mutate(RN = sample(1:k_h, 1)) |> 
  ungroup() 


region_summary |> 
  select(Region, prop_allocation, n_h, k_h, RN) |> 
  kable(caption="Evaluating Alternative Clustering Designs",
        align = "c", booktabs = TRUE) 
```

For each strata we use the random start to select the first school, and for stratum with more than one selection we use $RN, RN+k_h, RN+2k_h,...,RN +(n_h-1)$ until we satisfy $n_h$ selection.
Our minimum MOS `r round(m_opt, 2)` is also our $m_{opt}$ and we use it here to determine the minimum number of students in each selected school required and if this is not satisfy we perform post-selection linkage.
The linking is done by first selecting the number of schools in each strata.
When the next units on the list do not meet the sufficient MOS size required we move forward in the list until the first unit that meets the minimum requirement is achieved.
For all the units that did not meet the requirement they are cumulated backwards until a linked unit of minimum sufficient size is created.
We do this process for all strata.
Table 8 shows for each strata the total number of clusters, how many totaled schools linked and the total number of students.

```{r}
# linkings schools
sample_selected <- read_xlsx("~/work/d/SURV625project/data/sample_selected.xlsx")

# Required Students per School (m_h_star) to Maintain EPSEM:
region_summary <- region_summary |> 
  mutate(m_h_star=c(samp_frac*k_h))


region_min_MOS <- region_summary %>%
  group_by(Region) %>%
  mutate(
    min_MOS2 = ceiling(m_h_star /  0.7)  # Total response rate = 0.21, expanded sample size
  )

# Processing schools by region and generating clusters of links
linked_schools <- sample_selected %>%
  left_join(region_min_MOS, by = "Region") %>%  # Combined Minimum MOS
  group_by(Region) %>%
  mutate(
    # Initialize cumulative MOS and link tags
    cumulative_mos = cumsum(tot_all),
    need_link = if_else(tot_all < min_MOS2, 1, 0),
    # Dynamic generation of cluster IDs: linking when cumulative MOS is insufficient
    cluster_id = cumsum(
      if_else(
        cumulative_mos - lag(cumulative_mos, default = 0) >= min_MOS2 | row_number() == 1,
        1, 0
      )
    )
  ) %>%
  ungroup()
# Summarize the total MOS for each cluster and check for compliance
cluster_summary <- linked_schools %>%
  group_by(Region, cluster_id) %>%
  summarise(
    total_mos = sum(tot_all),
    schools = toString(BCODE),
    min_MOS2 = first(min_MOS2),
    .groups = "drop"
  ) %>%
  mutate(
    sufficient = if_else(total_mos >= min_MOS2, "Yes", "No")
  )
# Output clusters that need to be relinked (total MOS still insufficient)
clusters_to_relink <- cluster_summary %>% filter(sufficient == "No")

# Recursive linking until all clusters are up to standard
while (nrow(clusters_to_relink) > 0) {
  linked_schools <- linked_schools %>%
    group_by(Region) %>%
    mutate(
      cluster_id = if_else(
        cluster_id %in% clusters_to_relink$cluster_id,
        cluster_id + 1,  # Merge to the next cluster
        cluster_id
      )
    ) %>%
    ungroup()
  
  # Summary of recomputation clusters
  cluster_summary <- linked_schools %>%
    group_by(Region, cluster_id) %>%
    summarise(
      total_mos = sum(tot_all),
      schools = toString(BCODE),
      min_MOS2 = first(min_MOS2),
      .groups = "drop"
    ) %>%
    mutate(sufficient = if_else(total_mos >= min_MOS2, "Yes", "No"))
  
  clusters_to_relink <- cluster_summary %>% filter(sufficient == "No")
}

linked_schools |> 
  group_by(Region) |> 
  reframe(Clusters = max(cluster_id), Schools = n(), MOS = sum(tot_all)) |> 
    kable(caption="Linkage of Schools for Stage 1 Selection",
        align = "c", booktabs = TRUE) 

```

## Stage 2 Selection

To maintain equal probability of selection (epsem) across all strata, we computed the required number of students to be sampled per selected school, denoted as $m^*_h$ , based on the within-strata sampling fraction $f_h$, which is the same as the overall sampling fraction $f$ for all $h$, and the stratum-specific PPS sampling interval $k_h$ as follows:

$$
f_h = \frac{n_h MOS_{hi} }{\sum,_{i \in h} MOS{hi} } \frac{m^*_h}{MOS_{hi}}
 = \frac{n_h m^*_h}{\sum_{e \in h}} = m^*_h = f \times k_h
$$

This ensures that when each school is selected with probability proportional to its MOS and then students are sampled within school at a fixed rate $\frac{m^*_h}{MOS_{hi}}$, the overall inclusion probability for any student is:

$$
\pi_{i} = \frac{n_h \times MOS_{hi}}{\sum MOS_{hi}} \times \frac{m^*_h}{MOS_{hi}} = \frac{n_h m^*_h}{\sum MOS_h} 
$$Each student has the same selection probability within the state and within region $h$, satisfying the epsem condition.

### *Undersized Schools Linking*

In cases where a selected school had fewer students than the desired cluster size $m^*_h$, the within-school sampling rate would exceed 1.0, making the design unfeasible.
To address this, and to ensured that the effective number of completed questionnaires per school meets the targets $m^*_h$, we linked undersized schools with nearby schools when their MOS was less than $\frac{m^*_h}{r}$, where $r$ is the expected student response rate (70%).
This operational rule preserves feasibility without altering theoretical inclusion probabilities.
The within-school sampling rate remains $\frac{m^*_h}{MOS_{hi}}$, maintaining epsem across students.
For example, 5 small schools in Region 4 were linked to form a cluster of 10th meeting the required sample size of 19.729.
Table 9 shows the calculated $m^*_h$, the number of expected students, and the epsem validation for each of the nine regions.
These totals confirm that the expected completed sample size (sum ≈ 4,721) aligns with the original plan, and the design remains epsem-compliant across all regions.

```{r}
linked_schools |> 
  group_by(Region) |> 
  reframe(M_h_star = mean(m_h_star), n_h = mean(round(n_h))) |> 
  mutate("Expected Student" = M_h_star* n_h,
         "EPSEM Valid" = "True") |> 
  select(-n_h) |> 
   kable(caption="Stage 2 Selection of Students Within Strata",
        align = "c", booktabs = TRUE) 
```

### 

## Estimation Plan

For this proposal, we use the paired selection model to help us estimate variance.
However, we cannot form a pseudo-stratum from just one cluster nor have odd number of clusters, since paired methods require at least tow units within a stratum.
A key constraint for this approach is that each stratum must contain at least two independent variance units.
We collapse stratum that have odd number clusters or just one cluster with the adjacent stratum.
In Table 10 we show collapsed strata and corresponding number of sampling error computation units (SECU); we collapsed regions 1 to 3 into stratum 1, regions 4 to 7 into stratum 2, and left regions 8 and 9 the same.
We take all of the linked clusters and divide them by two to get the paired SECU count.
We now have a total of 4 strata in this model, 3 SECUs for stratum 1, 103 SECUS for stratum 2, 77 SECUS for stratum 3, and 135 SECUs for stratum 4 resulting in a total of 318 SECUs across strata.
In our estimation plan, each sampled unit (student) is assigned a stratum code indicating the explicit sampling stratum from which its PSU (clusters) was drawn.

```{r}

final_clusters <- linked_schools %>%
  group_by(Region, cluster_id) %>%
  summarise(
    linked_schools = paste(BCODE, collapse = ", "),
    total_mos = sum(tot_all),
    min_MOS2 = first(min_MOS2),
    .groups = "drop"
  ) %>%
  mutate(
    status = if_else(total_mos >= min_MOS2, "Valid", "Invalid")
  )


linked_schools <- linked_schools %>%
  left_join(
    cluster_summary %>% select(Region, cluster_id, total_mos),
    by = c("Region", "cluster_id")
  )

# Print results
final_clusters |> 
  group_by(Region) |> 
  reframe(Clusters = max(cluster_id)) |>  
  ungroup() |> 
  # collapse strata
  mutate(Psuedo = c(1, 1, 1, 2, 2, 2, 2, 3, 4)) |> 
  group_by(Psuedo) |> reframe(SECU = sum(Clusters)/2) |> 
    kable(caption="Evaluating Alternative Clustering Designs",
        align = "c", booktabs = TRUE) 

```

*Variance Estimation*

In this study, we need to estimate the proportion who have ever smoked, the proportion who have ever used marijuana, and the mean age at first use of cigarettes or marijuana.
We did not consider using weight here since we maintain epsem design through the whole sampling process, which means every student has the same probability of being selected.
However, in practice, we need to consider the response rate(the response rate among schools will be 30 percent, and the response rate among teenagers within schools will be 70 percent), which we should adjust our weight in design based on the response rate when conducting variance estimation.
We decided to use Taylor Series Linearization to estimate the ratio estimator, which is approximated as: $\text{For all strata } n_h = 2$

$$
\text{var}(r) \approx \frac{1}{\hat{t}_x^2} \left[ \sum_h \text{var}(\hat{t}_{h,y}) + r^2 \sum_h \text{var}(\hat{t}_{h,x}) - 2r \sum_h \text{cov}(\hat{t}_{h,y}, \hat{t}_{h,x}) \right]
$$

The general estimator used is the ratio estimator: $\hat{r} = \frac{\hat{t}_y}{\hat{t}_x}$

-   $\hat{t}_y$: estimated total for the numerator variable(e.g., number of students who smoked)

-   $\hat{t}_x$: estimated total for the denominator(e.g., total eligible students)

-   $\text{var}(\hat{t}_{h,y})$: variance of the numerator total within stratum $h$

-   $\text{var}(\hat{t}_{h,x})$:variance of the denominator total within stratum $h$

-   $\text{cov}(\hat{t}{h,y}, \hat{t}{h,x})$: covariance between numerator and denominator totals within stratum $h$

#### *Confidence Interval*

A 95% confidence interval for the estimated proportion and mean $\hat{r}$ is given by: $\hat{r} \pm t_{df, 0.975} \cdot \text{SE}(\hat{r})$, where, $SE(\hat{r}) = \sqrt{\text{Var}(\hat{r})}$, and the df is equal to the number of SECUs minus the number of strata, which is 318-4 = 314.
We conducted a simulation of the variance estimation of the proportion of students who ever smoked by applying the variance estimation formula, and we got: Ratio Estimator = 0.2505455, SE = 0.00003422286, 95% confidence interval \[0.2504782, 0.2506129\].

#### *Subclass Estimation*

For the 20% subgroup, we used the same estimation and variance formulas, but applied them to a subset of the data that reflects 20% of the full population(lower-income households).
However, the low-income students are only 20% of the population, which means some SECUs may contain a very small number of low-income students or no low-income students, thus, not meet the expected subclass size per cluster ( $\text{expected }b^* \text{subclass pct} = 76.66519 \times 0.20 = 15.33304$).
In that case, we might link undersized units to form linked units of the minimum sufficient size.
We print the roaster of names in the Appendix to save space here.

In conclusion, this report details a robust and statistically efficient two-stage stratified cluster sampling design tailored to the MDE's need for monitoring teenage smoking and drug use.
By employing stratification across educational regions, probability proportional to size selection for schools, and systematic sampling of students within schools, the design ensures representative statewide and regional estimates while adhering to budget constraints.
The chosen parameters, including an anticipated sample of approximately 88 schools and 4,721 students, are optimized to achieve the required precision for key variables after accounting for anticipated non-response.
The outlined procedures for selection, including linkage for smaller schools, and the comprehensive estimation plan provide a clear roadmap for survey implementation and analysis, ultimately delivering a cost-effective solution capable of generating the critical data required by the MDE.

## Appendix 1: Students Selected From One School.

```{r}

# Step 1:  Calculate how many students to sample
f_overall <- 0.0057
oneschool <- read_csv("~/work/d/SURV625project/data/schoolframe.csv")
MOS_7 <- 242
ACT_MOS_7 <- nrow(oneschool)
m_h_start_7 <- 16.05737

# Step 2: Sampling rate
sam_rate <- m_h_start_7/MOS_7

# Step 3: Expected sample size
m_exp <- sam_rate * ACT_MOS_7
m_exp_pra <- ceiling(m_exp)
# Step 2: Calculate sampling interval
k_interval <- ACT_MOS_7 / m_exp_pra
round_k_interval <- k_interval*10
round_mos <- 219*10+9



# Step 3: Random start between 1 and interval
set.seed(123)
start <- sample(1:round_k_interval, 1)

# Step 4: Select every `interval`-th student starting from `start`
indices <- seq(start, by = round_k_interval, length.out = m_exp_pra)
true_indices <- floor(indices/10)
sampled_students <- oneschool[true_indices, ]

# View sampled students
sampled_students |> 
  mutate_at(vars(3:5), str_to_title) |> 
  kable(caption="Evaluating Alternative Clustering Designs",
        align = "c", booktabs = TRUE) 
```
