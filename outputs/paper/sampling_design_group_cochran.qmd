---
title: "Michigan Teen Smoking and Drug Use Survey Sample Design"
format:
  jasa-pdf:
    keep-tex: true  
    journal:
      blinded: false
  jasa-html: default
date: last-modified
author:
  - name: Kevin Linares
  - name: Jianing Zou
  - name: Weishan Jiang
  - name: Xiaoqing Liu
    affiliations:
      - name: University of Maryland
abstract: |
  The State of Michigan Department of Education (MDE) requires data to monitor teenage smoking and drug use to assess compliance with tobacco industry settlements. This report outlines a two-stage stratified cluster sampling design developed for the MDE to monitor smoking and drug use among students in grades 7-12 statewide. The design addresses the need for cost-effective, statistically sound estimates at both the state and regional levels, meeting specified precision targets (CV=0.05) within a $500,000 budget. Schools were stratified into nine regions and selected with probability proportional to size (PPeS), followed by systematic selection of students within schools. The final design targets approximately 88 schools and 4,721 students, incorporating adjustments for non-response and procedures for handling undersized schools to maintain equal selection probabilities. The report details allocation, selection methods, and an estimation plan using a paired selection model for variance calculation. 
  
editor: 
  markdown: 
    wrap: sentence
---

```{r include=FALSE}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, comment = FALSE)

pacman::p_load(readxl, writexl, MESS, # used for linking
              kableExtra, viridis, ggthemes, knitr, sampling, tidyverse)

options(scipen=999)


```

## Introduction {#sec-intro}

The State of Michigan Department of Education (MDE) is specifically interested in three outcome variables; ever smoked one cigarette, every smoked marijuana, and age when first approach to smoke cigarettes or marijuana.
Moreover, MDE provided us with expected levels of precision means and coefficient of variation (CV=0.05) shown in Table 1.

```{r}

# build dataframe with inputs
MI_school_samples <- tibble(
  Outcome = c("smoked_cig", "smoked_mj", "age_approached"),
  type = c("prop", "prop", "mean"),
  desire_cv = rep(.05, 3),
  expect_mean = c(.25, .15, 12),
) 

MI_school_samples |> 
  kable(caption="Key Variables and Desired Levels of Precision ",
        col.names = c("Outcome", "Type", "Desired CV", "Expected Mean"),  
        align = "c", booktabs = TRUE) 


MI_school_samples <- MI_school_samples |> 
  mutate(
    # compute element variance
    var = if_else(type=="prop", # for proportions
                               expect_mean * (1 - expect_mean), 
                               if_else(type=="mean",# for means
                                       1^2, NA)),
    # compute stand dev
    sd = sqrt(var),
    # compute standard error
    se = desire_cv * expect_mean,
    # compute desired sample variance
    V = se^2,
    SRS_n = round(var / V))

MI_school_samples_variance_table <- MI_school_samples

```

From the desired levels of precision, we can compute the desired simple random sample (SRS) sample sizes when CV =.05 as $N = \frac{s^2}{se^2}$.
We first must calculate the element variance for each key variable.
For proportions we use $\hat{p}(1-\hat{p})$, while for age we square the estimated standard deviation of 1, $v(\bar{y}) = \sigma^2$.
We then calculate the standard error as $se(\hat{p}) = CV \times \hat{p}$.
Finally, we estimate the desired sampling variance as $var(\hat{p}) =  se(\hat{p})^2 \text{, where }  se(\hat{p}) = \sqrt{var(\hat{p})}$.
We show these results in Appendix 1, and note that these desired levels of precision would lead to large differences in sample sizes for each target variable.
Therefore, we may wish to consider a more complex survey design.

## Sampling Design {#sec-meth}

We employ a two-stage stratified cluster sampling design as it improve sample efficiency and representation by ensuring subgroups are included (i.e., stratification) while reducing costs and logistical challenges associated with sampling individuals across large geographic areas.
In the first stage, random selection of schools (e.g., Primary Sampling Units \[PSU\]) are determined by proportionate allocation for each strata.
The second stage randomly selects students (Secondary Selection Units \[SSU\]) from the selected school clusters within each region.

The MDE provided the 2024 7th through 12th grade student headcount for each public and private school within each of the nine regions resulting in a target frame of $830,138$ across $2,443$ schools (78% Public).
Schools in the first stage will be selected with probability proportional to student body size (PPeS).
The proportionate allocation $M_h / \sum M_h$ where $M_h$ is the total number of students in stratum $h$, will be used to determine school number selection in the first stage.
Appendix 2 presents for each of the 9 strata total students, number of schools, and proportionate allocation.

```{r}

school_frame <- read_xls(
  "~/work/d/SURV625project/data/MI_school_frame_head_counts.xls")


# region counts
strata_Prop_allocate <- school_frame |> 
  group_by(Region) |> 
  reframe(M_h = sum(tot_all), # total of students in stratum
         N_h = n()) |> # total of schools in stratum
  mutate(prop_allocation = M_h/sum(M_h)) 

```

We obtained design effects (DEFF) estimates (DEFF_cig=2.5, DEFF_mj=2.0, DEFF_age=1.7) from a similar pilot study of 7,500 students based on 150 schools with 50 students each, and based on these we estimate the rate of homogeneity $roh$ for each target variable.
We use the provided DEFFs to estimate $roh$ as $\hat{roh} = \frac{DEFF-1}{m-1}$, where $m$ is the total sampled students in the pilot study, to consider alternative cluster sample designs along with cost considerations.
Appendix 3 provides the $roh$ estimate for each target variable.

```{r}
nm <- 7500
n <- 150
m <- nm / n

MI_school_samples <- MI_school_samples |> 
  # add deff and roh to our table
  mutate(desire_deff = c(2.5, 2.0, 1.7),
         # compute roh
         roh = (desire_deff - 1) / (m - 1),
         )
```

### *Sampling Within Budget*

Recall that our budget cost constraints as the cost per cluster as $c_n = \$3,000$ and cost per student as $c_m = \$50$, with a total budget constraint of $C = \$500,000$.
We can use the $roh$estimates along with these costs to estimate the optimum subsample size $m_{opt}$ needed to achieve the desired precision as $m_{opt} = \sqrt{\frac{c_n}{c_m} \frac{1-roh}{roh}}$.
Note that since we have three target variables we also have three separate $roh$ estimates and thus three $m_{opt}$ estimates.
Similarly, we can use $m_{opt}$ to estimate the number of schools $n_{opt}$ to sample, $n_{opt} = \frac{C}{c_n + m_{opt} \times c_m}$ .
Finally, we compute new DEFF for each variable as $roh$ is portable and since we already computed $m_{opt}$ as $DEFF_{new} = 1 + (m_{opt} - 1) \times roh$.
By multiplying $m_{opt} \times n_{opt}$ for each variable we also get the total subsample size, as well as compute the total cost using $n_{opt} \times c_n + n_{opt} \times m_{opt} \times c_m$.
Table 2 shows for each target variable $m_{opt}$, $n_{opt}$, $DEFF_{new}$, total subsample size denoted by $total_{nm}$, and the total cost.
Notice that our $DEFF_{new}$ estimates are close to those from the pilot study since again we used these to compute $roh$ which is portable for estimating new design effects.

```{r}

c_n = 3000 # cost per cluster
c_m = 50 # cost per element within cluster
C = 500000 # total budget

MI_school_samples <- MI_school_samples |> 
  mutate(
    # compute optimum m size
    m_opt = sqrt( (c_n / c_m) * ( (1-roh)/roh) ),
    n_opt = C / (c_n + m_opt * c_m),
    # compute new deff
    deff_new = 1 + (m_opt-1) * roh,
     # compute total SSU
    total_nm = m_opt * n_opt)

MI_school_samples |> 
  select(Outcome, m_opt, n_opt, deff_new, total_nm) |> 
  mutate(cost = (c_n * n_opt) + (c_m * n_opt * m_opt),
         cost = scales::dollar(cost),
         Outcome = ifelse(Outcome == "age_approached_to_smoke", 
                          "age_smoke", Outcome),
         Option = 1:3) |>
  kable(caption="Estimating New DEFF and Total Cost",
        align = "c", booktabs = TRUE) 

# note, 88 * c_n + 88 * 53 * c_m = $497,200
```

### *Evaluating Alternative Clustering Designs*

We have the possability of three clustering design options to choose from based on the target variables.
Using the $m_{opt}$ values from Table 2 as our three options, we iterate over each set of target variables using these values to recompute for each target variable a new design effect and evaluate the estimated sampling variance for each design.
We estimate the SRS sampling variance as $var_{srs} = \frac{var}{total_{nm} - 1}$ where var is the sampling variance calculated from the pilot study and the denominator is the degrees of freedom.
Additionally, we estimate the sampling variance for the clustering design as $var_{crs} = var_{srs} \times deff_{new}$.
After estimating $var_{crs}$, we can square it to estimate a standard error, $se=\sqrt{var_{crs}}$ to use to estimate 95% confidence intervals for the estimated means.
Additionally, in our evaluation of $m_{opt}$ we can determine if the estimated sampling variance from the complex design is smaller than what is desired from MDE; therefore, Appendix 4 shows sampling variances, standard errors, confidence intervals, and a variance check (e.g., "Y" = yes if \<= to desired sampling variance) for each target variable using the $m_{opt}$ options.

```{r}
# total pop
N <- school_frame |> tally(tot_all) |> pull()

# optimum n
total_nm <- MI_school_samples |> 
  slice(2) |> # second design option 
  summarise(m_opt*n_opt) |> 
  pull()

samp_frac <- total_nm / N
```

We determine that option 2 has reasonable estimated design effects comparable to those from the pilot study as well as it is the only option to pass the estimated sampling variance check we designed.
Option 2 with $m_{opt} = 53, n_{opt} = 88$ would cost a total of \$497,200.
Since the total student population is `r N` and our now target sample is `r round(total_nm)` we can estimate the sampling fraction to be $f = n/N$ = `r samp_frac`.
The sampling fraction is the ratio of the sample size to the population size, and this estimate translates to the sample comprises approximately 0.57% of the total student population.
In this case, the sampling fraction is low and the finite population correction factor is not needed for calculating variances to adjust for the fact that sampling without replacement from a finite population reduces variability compared to sampling from an infinite population.

### *Non-Response Adjustments*

```{r}
# response rates
school_rr <- .30
student_rr <- .70
# Given values
n_opt <- MI_school_samples |> 
  slice(2) |> select(n_opt) |> 
  pull() / school_rr

m_opt <- MI_school_samples |> 
  slice(2) |> select(m_opt) |> 
  pull() / student_rr


```

The MDE anticipates 30% school response rates and 70% among students; therefore, we adjust the number of schools and within-school target by dividing$m_{opt} \times RR_{student} = 53.6766 \div .70$ = `r m_opt` students and for schools $n_{opt} \times RR_{schools} =  87.9689 \div .30$ = `r n_opt`.
We use these values to allocate the number of clusters for each strata based on the proportion allocated we calculated.

## Stage 1 Selection

We consider stratified PPeS selection of schools from each strata by first sorting the list of schools to achieve implicit stratification.
We sort by taking the number of 9th through 12th grade for each school divided by the total student body and descending order, and in this way we hypothesize that schools with older students are more likely to be positively associated with the target variables.
For each strata $h$ we assign our adjusted $n_{opt} \times proportionate \_ allocation$ estimated earlier to calculate the number of schools to sample, denoted as $n_h$ in Appendix 5.
We use $n_h$ to calculated in this Table the sampling interval $k_h = \frac{\sum_{i \ in h} MOS_{hi}}{n_h}$ where $MOS_{hi}$ is the measure of size (MOS), total student head-count, for each school $i$ in strata $h$.
The $k_h$ parameter is an important component of systematic sampling to determine how frequently units are selected from an ordered list.
We randomly select a number between 1 and $k_h$ for selecting schools from the list, denoted as $RN$.

```{r}
set.seed(9999) 

# Compute proportional allocation of clusters to each stratum
region_summary <- strata_Prop_allocate |> 
  # Ensure at least 1 cluster per
  mutate(n_h = n_opt * prop_allocation,
                     N_h = as.double(N_h)) |> 
  group_by(Region) |> 
  reframe(across(where(is.double), ~ sum(.x))) |> 
  mutate(k_h = M_h / round(n_h),) |>    # zone size
  # create random start values
  rowwise() |> 
  mutate(RN = sample(1:k_h, 1)) |> 
  ungroup() 

```

For each strata we use the random start to select the first school, and for stratum with more than one selection we use $RN, RN+k_h, RN+2k_h,...,RN +(n_h-1)$ until we satisfy $n_h$ selection.
Our minimum MOS `r round(m_opt, 2)` is also our $m_{opt}$ and we use it here to determine the minimum number of students in each selected school required and if this is not satisfied we perform post-selection linkage.
The linking is done by first selecting the number of schools in each strata.
When the next units on the list do not meet the sufficient MOS required we move forward in the list until the first unit that meets the minimum requirement is achieved.
For all the units that did not meet the requirement they are cumulated backwards until a linked unit of minimum sufficient size is created.
We do this process for all strata.
Appendix 6 shows for each strata the total number of clusters, how many totaled schools linked and the total number of students.

```{r}
# linkings schools
sample_selected <- read_xlsx("~/work/d/SURV625project/data/sample_selected.xlsx")

# Required Students per School (m_h_star) to Maintain EPSEM:
region_summary <- region_summary |> 
  mutate(m_h_star=c(samp_frac*k_h))


region_min_MOS <- region_summary %>%
  group_by(Region) %>%
  mutate(
    min_MOS2 = ceiling(m_h_star /  0.7)  # Total response rate = 0.21, expanded sample size
  )

# Processing schools by region and generating clusters of links
linked_schools <- sample_selected %>%
  left_join(region_min_MOS, by = "Region") %>%  # Combined Minimum MOS
  group_by(Region) %>%
  mutate(
    # Initialize cumulative MOS and link tags
    cumulative_mos = cumsum(tot_all),
    need_link = if_else(tot_all < min_MOS2, 1, 0),
    # Dynamic generation of cluster IDs: linking when cumulative MOS is insufficient
    cluster_id = cumsum(
      if_else(
        cumulative_mos - lag(cumulative_mos, default = 0) >= min_MOS2 | row_number() == 1,
        1, 0
      )
    )
  ) %>%
  ungroup()
# Summarize the total MOS for each cluster and check for compliance
cluster_summary <- linked_schools %>%
  group_by(Region, cluster_id) %>%
  summarise(
    total_mos = sum(tot_all),
    schools = toString(BCODE),
    min_MOS2 = first(min_MOS2),
    .groups = "drop"
  ) %>%
  mutate(
    sufficient = if_else(total_mos >= min_MOS2, "Yes", "No")
  )
# Output clusters that need to be relinked (total MOS still insufficient)
clusters_to_relink <- cluster_summary %>% filter(sufficient == "No")

# Recursive linking until all clusters are up to standard
while (nrow(clusters_to_relink) > 0) {
  linked_schools <- linked_schools %>%
    group_by(Region) %>%
    mutate(
      cluster_id = if_else(
        cluster_id %in% clusters_to_relink$cluster_id,
        cluster_id + 1,  # Merge to the next cluster
        cluster_id
      )
    ) %>%
    ungroup()
  
  # Summary of recomputation clusters
  cluster_summary <- linked_schools %>%
    group_by(Region, cluster_id) %>%
    summarise(
      total_mos = sum(tot_all),
      schools = toString(BCODE),
      min_MOS2 = first(min_MOS2),
      .groups = "drop"
    ) %>%
    mutate(sufficient = if_else(total_mos >= min_MOS2, "Yes", "No"))
  
  clusters_to_relink <- cluster_summary %>% filter(sufficient == "No")
}

```

## Stage 2 Selection

We assume rosters are made available by the school administration at the time of data collection.
These rosters are ordered and formatted uniformly to facilitate systematic sampling.
To maintain equal probability of selection (epsem) across all strata, we computed the required number of students to be sampled per selected school, denoted as $m^*_h$ , based on the within-strata sampling fraction $f_h$, which is the same as the overall sampling fraction $f$ for all $h$, and the stratum-specific PPS sampling interval $k_h$ as follows, $f_h = \frac{n_h MOS_{hi} }{\sum_{i \in h} MOS{hi} } \frac{m^*_h}{MOS_{hi}} = \frac{n_h m^*_h}{\sum_{e \in h}MOS_{hi}} \Rightarrow m^*_h = f \times k_h$.
This ensures that when each school is selected with probability proportional to its MOS and then students are sampled within school at a fixed rate $\frac{m^*_h}{MOS_{hi}}$, the overall inclusion probability for any student is, $\pi_{i} = \frac{n_h \times MOS_{hi}}{\sum MOS_{hi}} \times \frac{m^*_h}{MOS_{hi}} = \frac{n_h m^*_h}{\sum MOS_h}$.
Each student has the same selection probability within the state and within region $h$, satisfying the epsem condition.
Table 3 summarizes the first stage stratification and selection for two strata.
The tolerated minimum number of students per school is estimated as $m^*_h$ divided by the expected student response rate of 0.70 and is denoted as b_h in the table.
Additionally, we compute the sampling interval for each stratum to achieve epsem, as well as show the random start used to select schools.

```{r}
linked_schools |> 
  filter(Region %in% c(3, 4)) |> 
  group_by(Region) |> 
  reframe(f_h =  max((n_h * m_h_star) /sum(MOS)),
         MOS_h = sum(MOS), 
         n_h = max(n_h),
         b_h = max(m_h_star / 0.70),
         k_h = max(k_h), 
         RN = max(RN)) |> 
  kable(caption="Sampling Interval for Two Strata,",
        align = "c", booktabs = TRUE) 
```

### *Undersized Schools Linking*

In cases where a selected school had fewer students than the desired cluster size $m^*_h$, the within-school sampling rate would exceed 1.0, making the design unfeasible.
To address this, and to ensured that the effective number of completed questionnaires per school meets the targets $m^*_h$, we linked undersized schools with nearby schools when their MOS was less than $\frac{m^*_h}{r}$, where $r$ is the expected student response rate (70%).
This operational rule preserves feasibility without altering theoretical inclusion probabilities.
The within-school sampling rate remains $\frac{m^*_h}{MOS_{hi}}$, maintaining epsem across students.
For example, 5 small schools in Region 4 were linked to form a cluster of 10 meeting the required sample size of 19.729.
Note that no oversize schools were identified that required splitting, and all selected schools acceptable size or linked as needed.
Appendix 8 presents the within school sampling rate for the two selected strata in Appendix 7.

```{r}
final_output <- linked_schools |> 
  group_by(Region, cluster_id) |>
  mutate(
    Selection_Number = cur_group_id(),
    Cluster_Cumulative_Mos = sum(tot_all),
    Within_school_interval = sum(tot_all) / first(m_h_star),
    Schools_in_Cluster = paste(BCODE, collapse = ", "),
  ) |>
  ungroup() %>%
  arrange(Region, Selection_Number) |>
  select(
    Selection_Number,
    Region = Region, 
    School = BCODE,
    Cluster_Cumulative_Mos,
    Cumulative_Mos = cumulative_mos,
    m_h_star,
    Within_school_interval,
    Schools_in_Cluster
  ) |>
  distinct(Selection_Number, .keep_all = TRUE)

```

### Student Selection Sample

We implement the same systematic random sampling for the roster example of schools from Region 7.
The randomly sampled middle school was from Region 7, the MOS for this school was 242, but the actual size is 219.
This is the formula for calculating overall sampling fraction: $f_h = \frac{n_h MOS_{hi} }{\sum_{i \in h} MOS{hi} } \frac{m^*_h}{MOS_{hi}}$.
We got the expected sample size of 14.53126, and we rounded it to 15.
To obtain the expected sample size, we first got the second-stage sampling rate is $\text{Sampling Rate} = \frac{m^*_{7}}{MOS_7} = \frac{16.05737}{242} = 0.06635277$, and then multiplied the rate by the actual sample size.

To get the sampling interval $k_{hi} = MOS_{hi} / m^*_{h} = \frac{219}{15}$, we choose a random starting number between 1 and $k_{hi}$, which is 14.6, then we use the k-interval 146 to conduct the systematic sampling.
Then we selected the student at the random start position (14) and every $k_{hi}$-th student thereafter from the ordered roster.
The roaster of names is in Appendix 9.

## Estimation Plan

For this proposal, we use the paired selection model to help us estimate variance.
However, we cannot form a pseudo-stratum from just one cluster nor have odd number of clusters, since paired methods require at least two units within a stratum.
A key constraint for this approach is that each stratum must contain at least two independent variance units.
We collapse strata that have odd number clusters or just one cluster with the adjacent stratum.
In Appendix 7, we show collapsed strata and corresponding number of sampling error computation units (SECU); we collapsed regions 1 to 3 into stratum 1, regions 4 to 7 into stratum 2, and left regions 8 and 9 the same.
We take all of the linked clusters and divide them by two to get the paired SECU count.
We now have a total of 4 strata in this model, 3 SECUs for stratum 1, 103 SECUs for stratum 2, 77 SECUs for stratum 3, and 135 SECUs for stratum 4 resulting in a total of 318 SECUs across strata.
In our estimation plan, each sampled unit (student) is assigned a stratum code indicating the explicit sampling stratum from which its PSU (clusters) was drawn.

```{r}

final_clusters <- linked_schools %>%
  group_by(Region, cluster_id) %>%
  summarise(
    linked_schools = paste(BCODE, collapse = ", "),
    total_mos = sum(tot_all),
    min_MOS2 = first(min_MOS2),
    .groups = "drop"
  ) %>%
  mutate(
    status = if_else(total_mos >= min_MOS2, "Valid", "Invalid")
  )


linked_schools <- linked_schools %>%
  left_join(
    cluster_summary %>% select(Region, cluster_id, total_mos),
    by = c("Region", "cluster_id")
  )


```

#### *Variance Estimation*

In this study, we need to estimate the proportion who have ever smoked, the proportion who have ever used marijuana, and the mean age at first use of cigarettes or marijuana.
We did not consider using weight here since we maintained epsem design through the whole sampling process, which means every student has the same probability of being selected.
However, in practice, we need to consider the response rate(the response rate among schools will be 30 percent, and the response rate among teenagers within schools will be 70 percent), which we should adjust our weight in design based on the response rate when conducting variance estimation.
We decided to use Taylor Series Linearization to estimate the ratio estimator, which is approximated as: $\text{For all strata } n_h = 2$.

$$
\text{var}(r) \approx \frac{1}{\hat{t}_x^2} \left[ \sum_h \text{var}(\hat{t}_{h,y}) + r^2 \sum_h \text{var}(\hat{t}_{h,x}) - 2r \sum_h \text{cov}(\hat{t}_{h,y}, \hat{t}_{h,x}) \right]
$$

The general estimator used is the ratio estimator: $\hat{r} = \frac{\hat{t}_y}{\hat{t}_x}$

-   $\hat{t}_y$: estimated total for the numerator variable(e.g., number of students who smoked)

-   $\hat{t}_x$: estimated total for the denominator(e.g., total eligible students)

-   $\text{var}(\hat{t}_{h,y})$: variance of the numerator total within stratum $h$

-   $\text{var}(\hat{t}_{h,x})$:variance of the denominator total within stratum $h$

-   $\text{cov}(\hat{t}{h,y}, \hat{t}{h,x})$: covariance between numerator and denominator totals within stratum $h$

#### *Confidence Interval*

A 95% confidence interval for the estimated proportion and mean $\hat{r}$ is given by: $\hat{r} \pm t_{df, 0.975} \cdot \text{SE}(\hat{r})$, where, $SE(\hat{r}) = \sqrt{\text{Var}(\hat{r})}$, and the df is equal to the number of SECUs minus the number of strata, which is 318-4 = 314.
We conducted a simulation of the variance estimation of the proportion of students who ever smoked by applying the variance estimation formula, and we got: Ratio Estimator = 0.2505455, SE = 0.00003422286, 95% confidence interval \[0.2504782, 0.2506129\].

#### *Subclass Estimation*

For the 20% subgroup, we used the same estimation and variance formulas, but applied them to a subset of the data that reflects 20% of the full population(lower-income households).
However, the low-income students are only 20% of the population, which means some SECUs may contain a very small number of low-income students or no low-income students, thus, may not meet the expected subclass size per cluster ( $\text{expected }b^* \text{subclass pct} = 76.66519 \times 0.20 = 15.33304$).
In that case, we might link undersized units to form linked units of the minimum sufficient size.

In conclusion, this report details a robust and statistically efficient two-stage stratified cluster sampling design tailored to the MDE's need for monitoring teenage smoking and drug use.
By employing stratification across educational regions, probability proportional to size selection for schools, and systematic sampling of students within schools, the design ensures representative statewide and regional estimates while adhering to budget constraints.
The chosen parameters, including an anticipated sample of approximately 88 schools and 4,721 students, are optimized to achieve the required precision for key variables after accounting for anticipated non-response.
The outlined procedures for selection, including linkage for smaller schools, and the comprehensive estimation plan provide a clear roadmap for survey implementation and analysis, ultimately delivering a cost-effective solution capable of generating the critical data required by the MDE.

\newpage

## Appendix 1: Estimating SRS Desired Sample Size

For each target variable alongside desired levels of means and sampling variance we display below the element variance, standard deviation and standard error, and sampling variance.
We use the sampling variance as the denominator to determine SRS sampling size for each target variable.

```{r}

MI_school_samples_variance_table |> 
  select(-2:-4 ) |> 
  kable(col.names = c("Outcome", "Element Variance", "SD", "SE", "Variance", 
                      "SRS N"),  
        align = "c", booktabs = TRUE) 
```

\newpage

## Appendix 2: Proportionate Allocation Across Strata

We compute a proportionate allocation of students across all nine strata.
For instance, 45% of students across 923 schools in this population come from stratum 9; therefore, the proportionate allocation for this stratum is .4514 in the below table.

```{r}

strata_Prop_allocate |> 
   kable(col.names = c("Region", "Total Student", "Total Schools", 
                      "Proportionate Allocation"),  
        align = "c", booktabs = TRUE) 

```

\newpage

## Appendix 3: We Use Pilot Study DEFFs to Estimate roh

We estimate roh form the design effects provided from a similar pilot study.
Below we show roh estimates for each target variable.

```{r}

MI_school_samples |> 
  select(Outcome, desire_deff, roh) |>  
    kable(col.names = c("Outcome", "DEFF", "roh"),  
        align = "c", booktabs = TRUE) 
```

\newpage

## Appendix 4: Evaluating Alternative Clustering Designs

The table below presents the three optimum subsample sizes for each target variable alongside estimates of sampling variance, standard errors, and a variance check to determine which option is optimal for this design.

```{r}

map_dfr(seq(1,3), function(x){
  
  MI_school_samples |> 
  # we can print projected total cost for n=50
  mutate(m_opt = m_opt[x], # optimum m from first row
         n_opt = n_opt[x],
         total_nm = m_opt*n_opt,
         # calculate new deff
         deff_new = 1 + (m_opt-1) * roh,
         # recalcualte element variance
         var = c(.24, .1275, 9),
         # calcualte SRS variance
         var_srs =  var / (total_nm - 1),
         # calculate complex design variance
         var_crs = var_srs * deff_new,
          # compute confidence intervals
         se = sqrt(var_crs),
         lower = expect_mean  - 1.96*se,
         upper = expect_mean + 1.96*se,
        # flag if var_crs is lower or = to desired sampling var
         var_ck = ifelse(var_crs <= V, "Y", "N"),
        Option = x,
  ) 
    
  
}) |> 
  select(Outcome, Option, deff_new, var_srs, var_crs, se, lower, upper, var_ck) |> 
  mutate_at(3:8, round, 6) |> 
  kable(align = "c", booktabs = TRUE) 
```

\newpage

## Appendix 5: Strata Cluster Selection, Sampling Interval

We calculate using the proportionate allocation and n_opt the number of clusters to select from each strata.
Additionally, we compute sampling intervals and select random starts from 1 to k.

```{r}
region_summary |> 
  select(Region, n_h, k_h, RN) |> 
  kable(align = "c", booktabs = TRUE) 
```

\newpage

## Appendix 6: Linkage of Schools for Stage 1 Selection

We show the number of clusters to be sampled for each strata along with the number of total linked schools and total number of students in each strata to use for random selection in the second stage.

```{r}

linked_schools |> 
  group_by(Region) |> 
  reframe(Clusters = max(cluster_id), Schools = n(), MOS = sum(tot_all)) |> 
    kable(align = "c", booktabs = TRUE) 
```

\newpage

## Appendix 7: Evaluating Alternative Clustering Designs

We present a table with the following pseudo strata that were combined to used paired sampling, as well as the number SECUs associated.

```{r}

# Print results
final_clusters |> 
  group_by(Region) |> 
  reframe(Clusters = max(cluster_id)) |>  
  ungroup() |> 
  # collapse strata
  mutate(Psuedo = c(1, 1, 1, 2, 2, 2, 2, 3, 4)) |> 
  group_by(Psuedo) |> reframe(SECU = sum(Clusters)/2) |> 
    kable(align = "c", booktabs = TRUE) 
```

\newpage

## Appendix 8: Within-School Sampling Interval for 2 Strata

We show the selection of schools below after selection for two strata and within-school sampling rate.
The within-school sampling interval was calculated as the total student count divided by the target sample size (m_h_star).
Students were then selected systematically using a random start between 1 and the interval.

```{r}

final_output |>
  filter(Region %in% c(3, 4)) |> 
  select(Selection_Number, Region, School, Cumulative_Mos, Within_school_interval)|> 
   kable(col.names = c("Selection Num.", "Stratum", "School", "Cumul MOS", 
                        "Within School Interval"),
        align = "c", booktabs = TRUE) 
```

\newpage

## Appendix 9: Students Selected From One School.

```{r}

# Step 1:  Calculate how many students to sample
f_overall <- 0.0057
oneschool <- read_csv("~/work/d/SURV625project/data/schoolframe.csv")
MOS_7 <- 242
ACT_MOS_7 <- nrow(oneschool)
m_h_start_7 <- 16.05798

# Step 2: Sampling rate
sam_rate <- m_h_start_7/MOS_7

# Step 3: Expected sample size
m_exp <- sam_rate * ACT_MOS_7
m_exp_pra <- ceiling(m_exp)
# Step 2: Calculate sampling interval
k_interval <- ACT_MOS_7 / m_exp_pra
round_k_interval <- k_interval*10
round_mos <- 219*10+9



# Step 3: Random start between 1 and interval
set.seed(123)
start <- sample(1:round_k_interval, 1)

# Step 4: Select every `interval`-th student starting from `start`
indices <- seq(start, by = round_k_interval, length.out = m_exp_pra)
true_indices <- floor(indices/10)
sampled_students <- oneschool[true_indices, ]

# View sampled students
sampled_students |> 
  mutate_at(vars(3:5), str_to_title) |> 
  kable(caption="Evaluating Alternative Clustering Designs",
        align = "c", booktabs = TRUE) 
```
