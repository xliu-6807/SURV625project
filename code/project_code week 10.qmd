---
title: SURV625 Applied Sampling
date: "`r format(Sys.time(), '%d %B, %Y')`"
embed-resources: true
editor: visual
execute:
  warning: false
  error: false
  message: false
  tidy: true
format: pdf
---

```{r setup, include=FALSE}
pacman::p_load(readxl, writexl, MESS, knitr, sampling, tidyverse)

options(scipen=999)
```

## **SM 625: Week 4 Sampling Project Notes**

### For each of the three variables that will be the focus of the final course project, the Department of Education would like to generate estimates of means and proportions having a coefficient of variation of no more than 0.05. Using the numbers provided to you in the description of the final project, compute estimates of the element variances for each variable. Given these estimates, compute the desired level of precision (the desired sampling variance) for each estimate that corresponds to the desired coefficient of variation.

### Now, given the desired levels of precision for each estimate, compute estimates of the necessary sample sizes for each of these three estimates (assuming simple random sampling), ignoring the finite population correction. These will be starting points for the eventual two-stage cluster sample design.

### We first build a table to store our results for each week's assignments.

-   We also add the expected averages for each outcome variable.

```{r}

# build dataframe with inputs
MI_school_samples <- tibble(
  Outcome = c("smoked_cig", "smoked_mj", "age_approached_to_smoke"),
  type = c("prop", "prop", "mean"),
  desire_cv = rep(.05, 3),
  expect_mean = c(.25, .15, 12),
) 
  # calculate element 
MI_school_samples |> kable()
```

\

#### Our process is to:

-   1st, calculate the estimated element variance.

    -   For a proportion, to get the element variance we use $\hat{p}(1-\hat{p})$.
    -   For a mean, to get the element variance we simply just square the estimated standard deviation $v(\bar{y}) = \sigma^2$.

-   2nd, we calculate the estimated standard error as $se(\hat{p}) = CV \times \hat{p}$.

-   3rd, we compute the desired sampling variance as: $var(\hat{p}) =  se(\hat{p})^2 \text{, where }  se(\hat{p}) = \sqrt{var(\hat{p})}$

```{r}
MI_school_samples <- MI_school_samples |> 
  mutate(
    # compute element variance
    var = if_else(type=="prop", # for proportions
                               expect_mean * (1 - expect_mean), 
                               if_else(type=="mean",# for means
                                       1^2, NA)),
    # compute stand dev
    sd = sqrt(var),
    # compute standard error
    se = desire_cv * expect_mean,
    # compute desired sample variance
    V = se^2     
    )

MI_school_samples |> select(-type) |> kable()

```

We now estimate the desired sample sizes when we desire a CV =.05 as $n = \frac{s^2}{se^2}$

```{r}
MI_school_samples <- MI_school_samples |> 
  mutate(SRS_n = var / V)

MI_school_samples |> select(1, SRS_n) |> kable()
```

\newpage

## **SM 625: Week 5 Sampling Project Notes**

### For this week, we will consider the information available for stratified sampling of students. Eventually you are going to design a stratified cluster sample of students, where the clusters (or PSUs) are schools, but we aren‚Äôt there yet.

#### Recall the regions of interest in the sampling project description:

```{r}

school_frame <- read_xls(
  "MI_school_frame_head_counts.xls")

```

```{r, echo=FALSE}
school_frame |> 
  select(Region, County_ID) |> 
  group_by(Region) |> 
  distinct(County_ID) |> 
  arrange(County_ID) |> 
  summarise_all(toString) |> 
  kable() # note, county 42 has 0 schools
  
```

### As ‚ÄúState officials are interested in providing, if at all possible, separate estimates for each of nine education regions in the state, where the regions are defined by groups of counties‚Äù, we will use these nine regions as strata.

### Prepare a table that includes the:

-   Overall population counts in each of these nine strata (the total count of students in the target population at each school is in the tot_all column on the sampling frame).

-   Given these counts, once you have the working overall sample size (unknown for now and will be decided by your team next week), what is the proportionate allocation plan of that sample of students across these nine strata?

```{r}

# we will use Region, County_ID, and tot_all

# region counts
strata_Prop_allocate <- school_frame |> 
  group_by(Region) |> 
  reframe(M_h = sum(tot_all), # total of students in stratum
         N_h = n()) |> # total of schools in stratum
  mutate(prop_allocation = M_h/sum(M_h)) 

strata_Prop_allocate |> 
  kable()
# what is the proportionate allocation plan of that sample 
## of students across these nine strata?


```

\newpage

## **SM 625: Week 6 Sampling Project Notes**

### From a previous study, you obtain estimates of the following design effects for each of these three estimates:

-   proportion ever smoked one cigarette = 2.5;

-   proportion ever smoked marijuana = 2.0; and

-   mean age when first asked to smoke = 1.7.\

### This previous study featured a sample of size n = 7,500 students between the ages of 13 and 19, selected from a total of a = 150 clusters. Using this information, compute a synthetic estimate of roh for each of the three variables. These synthetic estimates of roh will be used to consider alternative cluster sample designs as you continue with your project work. Finally, budget and cost information is now available. The total budget for data collection for this project will be \$500,000. The client and the data collection organization estimate that the data collection will cost \$3,000 per primary stage cluster (school), and \$50 per completed questionnaire within a cluster. We will use this cost information moving forward for optimal subsample size calculations.

\

We can estimate the sample ICC or roh from the given design effect estimate as:

$$
\hat{roh} = \frac{deff-1}{m-1}
$$

We now that the sample total is $nm=7500$ and the sample number of cluster is $n=150$, which we can take the mean cluster size as $m = nm/n = 7500/150 = 50$ and use it to calculate $roh$.

```{r}
nm <- 7500
n <- 150
m <- nm / n

MI_school_samples <- MI_school_samples |> 
  # add deff and roh to our table
  mutate(desire_deff = c(2.5, 2.0, 1.7),
         # compute roh
         roh = (desire_deff - 1) / (m - 1)
         )

MI_school_samples |> select(Outcome, desire_deff, roh) |>  kable()
```

\newpage

## SM 625: Week 7 Sampling Project Notes

Recall that the client and the data collection organization estimated that the data collection would cost \$3,000 per primary stage cluster (school), and \$50 per completed questionnaire within a cluster. We will now use this information for optimum subsample size calculations. Recall that the total budget for data collection will be \$500,000.

Given this cost information and your estimates of roh for the three different variables of primary interest from last week, compute the optimum subsample size (and the corresponding optimal number of first stage clusters, given the total budget above) for each of the variables.

-   We now have budget constraints and denote the cost per cluster as $c_n = \$3,000$ and cost per element as $c_m = \$50$, with a total budget constraint of $C = \$500,000$. Since we know there are $n = 150$ clusters and a total sample size of $7,500$ students.

-   To compute the optimum $m$ size we use the following equation:

$$ 
m_{opt} = \sqrt{\frac{c_n}{c_m} \frac{1-roh}{roh}} 
$$

```{r}
c_n = 3000 # cost per cluster
c_m = 50 # cost per element within cluster
C = 500000 # total budget

MI_school_samples <- MI_school_samples |> 
  mutate(
    # compute optimum m size
    m_opt = sqrt( (c_n / c_m) * ( (1-roh)/roh) ),
    n_opt = C / (c_n + m_opt * c_m),
    # compute new deff
    deff_new = 1 + (m_opt-1) * roh,
     # compute total SSU
    total_nm = m_opt * n_opt)

MI_school_samples |> select(Outcome, roh, m_opt, n_opt) |> 
  kable()
```

**How will you decide on a single overall optimum subsample size to use in your design?**

-   Above we estimated the new design effects which range from 2.3 to 1.9, which are almost in line with our desired design effects of 2.5, 1.7. Below we print the new design effects, optimum number of cluster and cluster size, total sample size `total_nm`for our projected \$500,000 budget for all three outcome variables.
    -   Finally, we compute the sampling cost as $n \times c_n + n \times m \times c_m$ which we defined these terms above.

```{r}

MI_school_samples |> 
  select(Outcome, roh, m_opt, n_opt, deff_new, total_nm) |> 
  mutate(projected_cost = (c_n * n_opt) + (c_m * n_opt * m_opt),
         projected_cost = scales::dollar(projected_cost)) |> 
  mutate_at(2:6, round, 4) |> 
  kable()
```

\

**Think about a comparison of alternative cluster sample designs: under a fixed cost constraint, how would we decide which design would be best? What will be your overall sample size (n) under this new optimum subsample size?**

As you make progress in writing up what you have done so far, provide some discussion of the rationale for your choices in this regard.

Next, given this optimum subsample size and treating the values of roh as portable, compute the new expected DEFF for each estimate given the new design (this can be specific to each variable / estimate, given the different optimum subsample sizes). In addition, compute a new expected SRS variance for each variable under the new design, using the new ‚Äúoptimum‚Äù overall sample size (remember that you can treat the element variances for each variable estimated last week as portable). Finally, compute the new expected sampling variance for each estimate under this new cluster sample design. Are you still meeting the client‚Äôs precision requirements?

-   Given that we have three outcome variables, we also have three optimum number of clusters and cluster size estimates. That is, we can design and examine three options of different optimum number of clusters and cluster sizes.

-   We will use the portable roh estimate and calculate new design effects, SRS variance, and complex design variance for each outcome variable.

```{r, message=FALSE, warning=FALSE}
  
map(seq(1,3), function(x){
  
  MI_school_samples |> 
  select(Outcome, roh, m_opt, n_opt, total_nm) |> 
  # we can print projected total cost for n=50
  mutate(m_opt = m_opt[x], # optimum m from first row
         n_opt = n_opt[x],
         total_nm = m_opt*n_opt,
         # calculate new deff
         deff_new = 1 + (m_opt-1) * roh,
         # recalcualte element variance
         var = c(.24, .1275, 9),
         # calcualte SRS variance
         var_srs =  var / (total_nm - 1),
         # calculate complex design variance
         var_crs = var_srs * deff_new,
         #m_opt = round(m_opt)
         ) |>
    select(-roh, -var)  |> 
    mutate_at(2:3, floor) |> 
    mutate(total_nm = m_opt*n_opt) |> 
    mutate_at(5:7, round, 5) |> 
  kable()
  
}) |> 
  set_names(str_c(rep("Option ", 3), seq(1,3)))


```

We print standard error for the complex design with 95% confidence intervals, and we also flag whether the sampling variance from the clustering is equal or smaller than the desired sampling variance.

```{r}
map(seq(1,3), function(x){
  
  MI_school_samples |> 
  select(Outcome, expect_mean, V, roh, m_opt, n_opt, total_nm) |> 
  # we can print projected total cost for n=50
  mutate(m_opt = m_opt[x], # optimum m from first row
         n_opt = n_opt[x],
         total_nm = m_opt*n_opt,
         # calculate new deff
         deff_new = 1 + (m_opt-1) * roh,
        # recalcualte element variance
         var = c(.24, .1275, 9),
         # calcualte SRS variance
         var_srs =  var / (total_nm - 1) ,
         # calculate complex design variance
         var_crs = var_srs * deff_new,
         # compute confidence intervals
         se = sqrt(var_crs),
         lower = expect_mean  - 1.96*se,
         upper = expect_mean + 1.96*se,
        # flag if var_crs is lower or = to desired sampling var
         var_ck = ifelse(var_crs <= V, "yes", "no")) |>
    mutate_at(3:5, round, 4) |> 
  select(Outcome, expect_mean, se, lower, upper, var_ck) |> 
  kable()
  
}) |> 
  set_names(str_c(rep("Option ", 3), seq(1,3)))
```

\

-   Option 2 with a number of cluster of 87 and cluster size of 53 is the design we will choose given that the total sample size of 4,611 is within the allocated budget (\$491,550). We prefer this model because it stays close to the desired design effects we received from the customer. Additionally, the standard errors we estimate for this second option overall are the smallest resulting in tighter 95% confidence intervals for the expected estimates we were provided. This design in close to option 3, yet we prefer having a slightly smaller SSU if we can increase the number of PSUs sampled since this gives us a cost efficiency.\

The client has also provided other new information: the estimated size of the target population is N = 830,138. Given this population size and your overall sample size (n) under the new optimum subsample size computed above, what is your overall working sampling fraction (f)? Does it seem like finite population corrections will be necessary in your sampling variances if you choose to perform SRSWOR at some point?

```{r}
# total pop
N <- 830138

# optimum n
total_nm <- 4721
samp_frac <- total_nm / N; samp_frac

MI_school_samples |>  select(Outcome, expect_mean, roh, 
                             m_opt, n_opt, total_nm) |> 
  # we can print projected total cost for n=50
  mutate(m_opt = m_opt[2], # optimum m from first row
         n_opt = n_opt[2],
         total_nm = m_opt*n_opt,
         # calculate new deff
         deff_new = 1 + (m_opt-1) * roh,
         # recalcualte element variance
         var = c(.24, .1275, 9),
         # calcualte SRS variance with sampl_fraction
         var_srs =(1 - samp_frac) * var / (total_nm - 1),
         # calculate complex design variance
         var_crs = var_srs * deff_new,
         # compute confidence intervals
         se = sqrt(var_crs),
         lower = expect_mean  - 1.96*se,
         upper = expect_mean + 1.96*se ) |>
  select(Outcome, var_crs, se, lower, upper) |> 
  mutate_at(2:4, round, 5) |> 
  kable()
```

Our overall sampling fraction is .0057. In examining the complex design variances, and recalculating the expected standard error and 95% confidence interva given the sampling fractionl, it does not appear that accounting for a population correction makes a huge impact, and we suggest it will not be necessary in our sampling variance for an SRSWOR design

\newpage

## SM 625: Week 8 Sampling Project Notes

Assume that you will decide to allocate your final computed $n_{opt}$ number of clusters to each of the nine project strata based on the proportions of the total number of students in the population in each stratum (i.e., if 20% of the population of students comes from Region 1, you would sample 20% of your clusters from that region). Describe the first-stage sampling fractions for each stratum, where the total number of schools to sample at the first stage in each stratum is defined by your proportionate allocation of the $n_{opt}$ clusters.

Next your team should extend your design to consider stratified PPeS selection of schools from each of the nine strata at the first stage of your sample design.

You have been provided with a sampling frame that lists the schools within each region. Given the information on the sampling frame, how might you sort this list to achieve implicit stratification within the regions? You can treat the overall student count from a previous year (tot_all) as the measure of size for the PPeS sampling. Given this information, compute your zone size for systematic PPeS sampling within each of the nine strata (regions), and proceed with systematic selection based on fractional intervals to select the allocated number of schools within each stratum using PPeS sampling. What is your first-stage sampling fraction within each of the nine strata?

-   Using the proportionate allocation by strata computed earlier, we assign and add cluster allocation by stratum by $n_{opt} \times prop-allocation$.

-   nonresponse adjustment is achieved by taking our optimum values and adjusting them by the amount of respondents that are likely to complete the survey.

-   We also calculate the zone size which we label as k_h as:

    $$
    k_h = \frac{nMOS_i}{\sum_t MOS_i}
    $$

```{r}

set.seed(9999) 

# response rates
school_rr <- .30
student_rr <- .70
# Given values
n_opt <- round(87 / school_rr)
m_opt <- round(53 / student_rr)


# Compute proportional allocation of clusters to each stratum
region_summary <- strata_Prop_allocate |> 
  # Ensure at least 1 cluster per
  mutate(n_h = round(n_opt * prop_allocation),
           # we need to adjust the last n_h to get an exact 290
         n_h = ifelse(n_h == 131, n_h-1, n_h)) |> 
  mutate(N_h = as.double(N_h)) |> 
  group_by(Region) |> 
  reframe(across(where(is.double), ~ sum(.x))) |> 
  mutate(
         f_h = n_h / N_h,     # sampling fraction
         k_h =  round(M_h / n_h)) |>    # zone size
  # create random start values
  rowwise() |> 
  mutate(RN = sample(1:k_h, 1)) |> 
  ungroup()


region_summary |> 
  kable()
```

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAaCAYAAADFTB7LAAAAcElEQVR4Xu3OwQmAQAxE0bClWYCW5N06tM6V2YPg5CjoF/JhLoHAi6iqn9eOefUbqrYvHY0cQDLyAlKRNyARmYA0ZMLRkAlGQyaU72tkAtlim7r/vJqDUDjlKBROOQyFU2icQuMUGqfQuBEaV1XPOwEx96nYACK8+wAAAABJRU5ErkJggg== "Run Current Chunk")

-   To achieve implicit stratification we order the school list sorted by size of student in each region. To compute zone size we use

```{r}
school_frame_sorted <- school_frame |> 
  arrange(Region, desc(tot_all))

min_MOS <- m_opt

RN_sample <- map(1:nrow(region_summary), function(x){
  
  round(seq(region_summary$RN[x], 
      region_summary$M_h[x], 
      region_summary$k_h[x]))
})


```

```{r}
# we link the selected blocks
dat <- school_frame_sorted |>
  group_by(Region) |> 
  mutate(
    # assing ids
    id = row_number(),
    # flag if minimum MOS not met
    min_m_req = ifelse(tot_all >= min_MOS, 1 , 0),
    # create links and convert to clusters
    linking = lead(min_m_req, default=1),
    # assign clustering
    cluster = cumsum(lag(linking, default=1)),
    # add cumulative counts
    cumulative_max = cumsum(tot_all),
    cumulative_min = 1 + lag(cumulative_max, default = 0)    )
```

```{r}
dat_selected <- map_dfr(1:9, function(x){
  
  dat |> 
    filter(Region %in% x) |>  
    add_column(RN_sample[[x]] |> tibble() |> data.table::transpose()) |>
    # create flag for blocks that are selected
    mutate(selected =
             as.numeric(if_any(starts_with("V"), ~
                        between(.x, cumulative_min, cumulative_max)))) |>
    # drop select population elements
    select(-starts_with("V"))
  
})
```

```{r}
dat_linked <- dat_selected |>
  group_by(Region) |> 
  mutate(
    # flag if minimum MOS not met
    min_n_req = ifelse(tot_all >= min_MOS, 1 , 0),
    # create links and convert to clusters
    linking = lead(min_n_req, default=1),
    # assign clustering
    cluster = cumsum(lag(linking, default=1))) |> 
  ungroup()
```

```{r}
# show cluster of blocks selected, total HUs
sample_selected <- map_dfr(1:9, function(x){
  
   linkage = dat_linked |> 
    filter(Region %in%  x, selected==1) |> 
    select(Region, cluster) |> 
    mutate(Selection = RN_sample[[x]]) |> 
     pull(cluster)


  dat = dat_linked |>
  filter(Region %in% x,
         cluster %in% linkage) |>
  # now we link blocks within clusters
  group_by(cluster) |>
  # start clusters at 1
  mutate(cluster = cur_group_id()) |>
  # start with last id to link backwards
  arrange(desc(id)) 
  return(dat) 
}) |> 
  ungroup() 
  
 
```

```{r}
# Compute First-Stage Sampling Fractions
sampling_fractions <- sample_selected %>%
  group_by(Region) %>%
  summarise(sampled = n(),
            total = n_distinct(school_frame$BNAME[school_frame$Region == Region[1]]),
            sampling_fraction = sampled / total)

sampling_fractions
```

```{r}
# Form Pseudo-Strata for Paired Selection Model
pseudo_strata_df <- sample_selected %>%
  group_by(Region) %>%
  mutate(row_in_group = row_number(),
         pseudo_stratum_id = paste0("R", Region, "_P", ceiling(row_in_group / 2))) %>%
  ungroup()

pseudo_strata_df
```

¬∑\\newpage

## SM 625: Week 10 Sampling Project Notes

There are four primary tasks for your team to consider over the next week:

1.  Given your overall $m_{opt}$ $n_opt$ and N (based on the sampling frame), you‚Äôve already computed the overall sampling fraction, ùëì. For each of the nine strata, compute the required number of students to subsample from each sampled school based on the stratified PPeS design in order to maintain epsem across all strata.

-   Within strata, retain epsem for stratified PPS sampling across strata $f = f_h$ for all $h$.

$$
f_h = \frac{n_h MOS_{hi} }{\sum,_{i \in h} MOS{hi} } \frac{m^*_h}{MOS_{hi}} =\frac{m^*_h}{k_{h}}
$$

```{r}
# Required Students per School (m_h_star) to Maintain EPSEM:
region_summary<- region_summary%>% 
  mutate(m_h_star=c(samp_frac*k_h))
region_summary
```

2.  Do each of the schools that you sampled in a given region have the minimum sufficient size, given the stratum-specific subsample sizes computed in Task #1? Do subsequent schools on the list have the minimum sufficient size? If not, what will you do?

```{r}
region_min_MOS <- region_summary %>%
  group_by(Region) %>%
  mutate(
    min_MOS2 = ceiling(m_h_star / (0.3 * 0.7))  # Total response rate = 0.21, expanded sample size
  )

# Processing schools by region and generating clusters of links
linked_schools <- sample_selected %>%
  left_join(region_min_MOS, by = "Region") %>%  # Combined Minimum MOS
  group_by(Region) %>%
  arrange(desc(tot_all)) %>%  # Listed in descending order of MOS (prioritizing large schools)
  mutate(
    # Initialize cumulative MOS and link tags
    cumulative_mos = cumsum(tot_all),
    need_link = if_else(tot_all < min_MOS2, 1, 0),
    # Dynamic generation of cluster IDs: linking when cumulative MOS is insufficient
    cluster_id = cumsum(
      if_else(
        cumulative_mos - lag(cumulative_mos, default = 0) >= min_MOS2 | row_number() == 1,
        1, 0
      )
    )
  ) %>%
  ungroup()
# Summarize the total MOS for each cluster and check for compliance
cluster_summary <- linked_schools %>%
  group_by(Region, cluster_id) %>%
  summarise(
    total_mos = sum(tot_all),
    schools = toString(BCODE),
    min_MOS2 = first(min_MOS2),
    .groups = "drop"
  ) %>%
  mutate(
    sufficient = if_else(total_mos >= min_MOS2, "Yes", "No")
  )
# Output clusters that need to be relinked (total MOS still insufficient)
clusters_to_relink <- cluster_summary %>% filter(sufficient == "No")

# Recursive linking until all clusters are up to standard
while (nrow(clusters_to_relink) > 0) {
  linked_schools <- linked_schools %>%
    group_by(Region) %>%
    mutate(
      cluster_id = if_else(
        cluster_id %in% clusters_to_relink$cluster_id,
        cluster_id + 1,  # Merge to the next cluster
        cluster_id
      )
    ) %>%
    ungroup()
  
  # Summary of recomputation clusters
  cluster_summary <- linked_schools %>%
    group_by(Region, cluster_id) %>%
    summarise(
      total_mos = sum(tot_all),
      schools = toString(BCODE),
      min_MOS2 = first(min_MOS2),
      .groups = "drop"
    ) %>%
    mutate(sufficient = if_else(total_mos >= min_MOS2, "Yes", "No"))
  
  clusters_to_relink <- cluster_summary %>% filter(sufficient == "No")
}

final_clusters <- linked_schools %>%
  group_by(Region, cluster_id) %>%
  summarise(
    linked_schools = paste(BCODE, collapse = ", "),
    total_mos = sum(tot_all),
    min_MOS2 = first(min_MOS2),
    .groups = "drop"
  ) %>%
  mutate(
    status = if_else(total_mos >= min_MOS2, "Valid", "Invalid")
  )

# Print results
print(final_clusters)

linked_schools <- linked_schools %>%
  left_join(
    cluster_summary %>% select(Region, cluster_id, total_mos),
    by = c("Region", "cluster_id")
  )
```

```{r}
final_clusters|> 
  group_by(Region)|> 
  reframe(schools=n(),students=sum(total_mos))|> 
  knitr::kable()
```

3.  Begin to describe how you will physically select the subsample of students within a given sampled school (or set of linked schools). What will your second-stage sampling rate be for a given school within a given stratum? How will you acquire the updated rosters from each school? What technique will you use to select the sample at the specified second-stage rate?

```{r}
region_summary<- region_summary%>% 
  mutate(f_h_j=c(m_h_star/M_h))
region_summary
```

Selection Technique:

Systematic sampling is a suitable technique. For school hi:

-   Calculate the sampling interval k_hi = Mos_hi / n_h.

-   Choose a random starting number between 1 and k_hi.

-   Select the student at the random start position and every k_hi-th student thereafter from the ordered roster.

-   If schools are linked due to insufficient numbers, the rosters need to be combined and sampled uniformly.

-   Record unresponsive students and report adjusted weights.

4.  Write down the overall sampling fraction based on the stratified PPeS design, indicating the overall probability of inclusion for a given student, from a given school (or linked set of schools), in a given stratum. Be careful with notation. Keep in mind that the MOS values used for the sampled schools at the first stage and the denominator at the second stage (Did you sample a single school? Or a linked set of schools?) will depend on your response to Task #2 above

    The overall sampling fraction is $f = \frac{n}{N}=\frac{4721}{830138}$

    The probability of of inclusion for a given student is$P_{hi} = \frac{a_h*MoS_{hi}} {MoS_h} * \frac{m_h} {MoS_hi}= \frac{a_h*m_h} {MoS_h}$

```{r}
linked_schools<- linked_schools%>% 
  group_by(Region)%>%
  mutate(P_h = n_h*total_mos/M_h,
         P_i=m_h_star/total_mos,
         Prob=P_h*P_i,
         epsem_check = abs(Prob - mean(Prob)) < 1e-6)

stopifnot(all(linked_schools$epsem_check))

linked_schools |> 
  select(Region, BCODE, tot_all, m_h_star,n_h, min_MOS2, cluster_id,P_h,P_i, Prob,epsem_check) |> 
  knitr::kable()
16.27052*66+16.39564*130+16.29896*67+15.70182*12+15.36060	*7+20.25143+15.56534*2	+	16.36152*3+13.80805*2
```
